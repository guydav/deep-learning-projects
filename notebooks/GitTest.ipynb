{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GitTest.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guydav/deep-learning-projects/blob/master/notebooks/GitTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jktCXeszFiH2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kill -9 -1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zv2tQL6S4JAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "6f4ea7d5-f63c-4ddf-8807-b50fa3ba2fab"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!git clone https://github.com/guydav/deep-learning-projects.git\n",
        "!pip install -q -r deep-learning-projects/requirements.txt\n",
        "!wandb login 9676e3cc95066e4865586082971f2653245f09b4\n",
        "sys.path.extend(('./deep-learning-projects', './src/tqdm'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-learning-projects'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 37 (delta 11), reused 32 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (37/37), done.\n",
            "tcmalloc: large alloc 1073750016 bytes == 0x61b44000 @  0x7f9b0b28e2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "Branch 'colab' set up to track remote branch 'colab' from 'origin'.\n",
            "Switched to a new branch 'colab'\n",
            "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hrgh8Bj3EmVx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "0f4bc811-eb1d-4afc-8b5a-ce0a3fee1f6d"
      },
      "cell_type": "code",
      "source": [
        "!add-apt-repository -y ppa:alessandro-strada/google-drive-ocamlfuse-beta\n",
        "!apt-get update\n",
        "!apt-get install google-drive-ocamlfuse\n",
        "!apt-get -y install -qq fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "!google-drive-ocamlfuse -cc"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.26)] [Waiting for headers] [Co\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [2 InRelease 8,394 B/88.7 kB 9%] [Connecting to security.ubuntu.com (91.189.\r0% [1 InRelease gpgv 242 kB] [2 InRelease 11.3 kB/88.7 kB 13%] [Connecting to s\r                                                                               \rGet:3 http://ppa.launchpad.net/alessandro-strada/google-drive-ocamlfuse-beta/ubuntu bionic InRelease [15.4 kB]\n",
            "\r0% [1 InRelease gpgv 242 kB] [2 InRelease 17.1 kB/88.7 kB 19%] [Connecting to s\r                                                                               \rGet:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "\r0% [1 InRelease gpgv 242 kB] [2 InRelease 88.7 kB/88.7 kB 100%] [Connecting to \r0% [1 InRelease gpgv 242 kB] [Connecting to security.ubuntu.com (91.189.91.26)]\r                                                                               \rGet:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [83.2 kB]\n",
            "Get:7 http://ppa.launchpad.net/alessandro-strada/google-drive-ocamlfuse-beta/ubuntu bionic/main amd64 Packages [2,017 B]\n",
            "Ign:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [900 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [618 kB]\n",
            "Get:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [27.2 kB]\n",
            "Ign:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\n",
            "Hit:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  Release\n",
            "Hit:14 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [135 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [300 kB]\n",
            "Fetched 2,266 kB in 2s (1,243 kB/s)\n",
            "Reading package lists... Done\n",
            "Hit:1 http://ppa.launchpad.net/alessandro-strada/google-drive-ocamlfuse-beta/ubuntu bionic InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  InRelease\n",
            "Ign:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  Release\n",
            "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  google-drive-ocamlfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 1,246 kB of archives.\n",
            "After this operation, 6,494 kB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/alessandro-strada/google-drive-ocamlfuse-beta/ubuntu bionic/main amd64 google-drive-ocamlfuse amd64 0.7.1-0ubuntu3~ubuntu18.04.1 [1,246 kB]\n",
            "Fetched 1,246 kB in 1s (1,955 kB/s)\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 110842 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "Clearing cache...done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8DMTQ5ICFTky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "44c02e22-cf6f-4216-bc90-938e0726efa3"
      },
      "cell_type": "code",
      "source": [
        "!ls -la \"drive/Research Projects/Meta-Learning/v1/models\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 52\n",
            "drwxr-xr-x 2 root root 4096 Nov  9 18:46 .\n",
            "drwxr-xr-x 2 root root 4096 Nov  7 13:11 ..\n",
            "drwxr-xr-x 2 root root 4096 Nov  9 18:50 CNN_MLP\n",
            "drwxr-xr-x 2 root root 4096 Dec  9 16:53 data_augment_mse_larger_pooling_dropout_CNN_MLP\n",
            "drwxr-xr-x 2 root root 4096 Dec 13 19:56 large_batch_dimension_unit_larger_pooling_dropout_CNN_MLP\n",
            "drwxr-xr-x 2 root root 4096 Nov 27 23:09 larger_pooling_dropout_CNN_MLP\n",
            "drwxr-xr-x 2 root root 4096 Dec  4 14:46 mse_larger_pooling_dropout_CNN_MLP\n",
            "drwxr-xr-x 2 root root 4096 Nov 20 00:46 Pooling_Dropout_CNN_MLP\n",
            "drwxr-xr-x 2 root root 4096 Nov 21 23:31 pooling_dropout_decay_scheduler_CNN_MLP\n",
            "drwxr-xr-x 2 root root 4096 Nov 19 17:58 smaller_normalized_CNN_MLP\n",
            "drwxr-xr-x 2 root root 4096 Nov 28 23:13 task_subset_larger_pooling_dropout_CNN_MLP\n",
            "drwxr-xr-x 2 root root 4096 Dec 12 13:03 task_subset_mse_larger_pooling_dropout_CNN_MLP\n",
            "drwxr-xr-x 2 root root 4096 Dec 28 18:36 test_model_CNN_MLP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N-BriBo0FpNv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from projects.metalearning import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jU7R3CE4FW60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cb8c7b4f-b5c3-4ef3-afe5-81e2ad9f58fa"
      },
      "cell_type": "code",
      "source": [
        "normalized_train_dataset, train_dataloader, normalized_test_dataset, test_dataloader = dataset.create_normalized_datasets()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.4606134  0.45282578 0.44267213]\n",
            "[0.10389671 0.10068669 0.10868205]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZxQc5diHFW9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "15b2648b-3ebd-4f28-eb11-0ce9766845f4"
      },
      "cell_type": "code",
      "source": [
        "current_epoch = 0\n",
        "\n",
        "test_model = PoolingDropoutCNN_MLP(\n",
        "    query_length=23,\n",
        "    conv_filter_sizes=(16, 32, 48, 64),\n",
        "    conv_output_size=3072, \n",
        "    mlp_layer_sizes=(512, 512, 512, 512),\n",
        "    lr=1e-4, \n",
        "    weight_decay=1e-4, \n",
        "    # use_mse=True,\n",
        "    name='test_model_CNN_MLP')\n",
        "test_model.load_model(current_epoch)\n",
        "test_model.cuda()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n",
            "Warning: asked to load model with epoch 0. Ignoring...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PoolingDropoutCNN_MLP(\n",
              "  (conv): PoolingDropoutConvInputModel(\n",
              "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (batchNorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (batchNorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (batchNorm3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv4): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (batchNorm4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=3095, out_features=512, bias=True)\n",
              "  (fcout): SmallerDropoutFCOutputModel(\n",
              "    (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (fc4): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (fc5): Linear(in_features=512, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "xbnp_A2SFJYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f324edc1-9c5e-4f50-9aa3-0738423f7630"
      },
      "cell_type": "code",
      "source": [
        "total_epochs = 20\n",
        "wandb.init(project=\"meta-learning\")\n",
        "# wandb.config.update(dict(epochs=total_epochs), allow_val_change=True)\n",
        "\n",
        "base_model.train(test_model, train_dataloader, test_dataloader, \n",
        "      num_epochs=total_epochs - current_epoch, epochs_to_test=1, epochs_to_graph=10, \n",
        "      num_batches_to_print=2000, start_epoch=current_epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wandb: ERROR: Not authenticated.  Copy a key from https://app.wandb.ai/profile?message=true\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "API Key: ··········\n",
            "Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "W&B Run: https://app.wandb.ai/None/meta-learning/runs/7pjqixrs\n",
            "Call `%%wandb` in the cell containing your training loop to display live results.\n",
            "2018-12-28 18:42:29: After epoch 1, TRAIN average acc is 56.6735, average loss is 0.6834, and average AUC is 0.4999\n",
            "2018-12-28 18:43:25: After epoch 1, TEST average acc is 56.7619, average loss is 0.6819, and average AUC is 0.5001\n",
            "Resuming run: https://app.wandb.ai/guy/meta-learning/runs/7pjqixrs\n",
            "2018-12-28 18:47:30: After epoch 2, TRAIN average acc is 56.7483, average loss is 0.6815, and average AUC is 0.5000\n",
            "2018-12-28 18:48:09: After epoch 2, TEST average acc is 56.7143, average loss is 0.6812, and average AUC is 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EoUoVidCFaiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2009
        },
        "outputId": "aaf6dc1c-4ae3-4c3e-f150-d68146d8b18a"
      },
      "cell_type": "code",
      "source": [
        "!pip install --force -r deep-learning-projects/requirements.txt"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch (from -r deep-learning-projects/requirements.txt (line 1))\n",
            "  Using cached https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "tcmalloc: large alloc 1073750016 bytes == 0x6199c000 @  0x7f701e3102a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "Collecting torchvision (from -r deep-learning-projects/requirements.txt (line 2))\n",
            "  Using cached https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl\n",
            "Collecting torchsummary (from -r deep-learning-projects/requirements.txt (line 3))\n",
            "  Using cached https://files.pythonhosted.org/packages/7d/18/1474d06f721b86e6a9b9d7392ad68bed711a02f3b61ac43f13c719db50a6/torchsummary-1.5.1-py3-none-any.whl\n",
            "Collecting pyro-ppl (from -r deep-learning-projects/requirements.txt (line 4))\n",
            "Collecting wandb (from -r deep-learning-projects/requirements.txt (line 5))\n",
            "  Using cached https://files.pythonhosted.org/packages/5b/f0/f6562b8e987a82ad861d700c14d7408d5d338e6da96e432e2f6a1858629f/wandb-0.6.32-py2.py3-none-any.whl\n",
            "Obtaining tqdm from git+https://github.com/chengs/tqdm.git@colab#egg=tqdm (from -r deep-learning-projects/requirements.txt (line 6))\n",
            "  Updating ./src/tqdm clone (to revision colab)\n",
            "Collecting numpy (from torchvision->-r deep-learning-projects/requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 1.2MB/s \n",
            "\u001b[?25hCollecting pillow>=4.1.1 (from torchvision->-r deep-learning-projects/requirements.txt (line 2))\n",
            "  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting six (from torchvision->-r deep-learning-projects/requirements.txt (line 2))\n",
            "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "Collecting contextlib2 (from pyro-ppl->-r deep-learning-projects/requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\n",
            "Collecting opt-einsum>=2.3.0 (from pyro-ppl->-r deep-learning-projects/requirements.txt (line 4))\n",
            "Collecting networkx>=2.2 (from pyro-ppl->-r deep-learning-projects/requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/f4/7e20ef40b118478191cec0b58c3192f822cace858c19505c7670961b76b2/networkx-2.2.zip (1.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.7MB 2.5MB/s \n",
            "\u001b[?25hCollecting graphviz>=0.8 (from pyro-ppl->-r deep-learning-projects/requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/e2/ef2581b5b86625657afd32030f90cf2717456c1d2b711ba074bf007c0f1a/graphviz-0.10.1-py2.py3-none-any.whl\n",
            "Collecting sentry-sdk>=0.4.0 (from wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "  Using cached https://files.pythonhosted.org/packages/97/bd/62edcd0a2825d9212291ed61fea08cab22d52b2a578a6f1ccf54effa3462/sentry_sdk-0.6.5-py2.py3-none-any.whl\n",
            "Collecting requests>=2.0.0 (from wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 20.4MB/s \n",
            "\u001b[?25hCollecting watchdog>=0.8.3 (from wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "Collecting python-dateutil>=2.6.1 (from wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "  Using cached https://files.pythonhosted.org/packages/74/68/d87d9b36af36f44254a8d512cbfc48369103a3b9e474be9bdfe536abfc45/python_dateutil-2.7.5-py2.py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3 (from wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "Collecting Click>=6.0 (from wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 24.1MB/s \n",
            "\u001b[?25hCollecting nvidia-ml-py3>=7.352.0 (from wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "Collecting gql>=0.1.0 (from wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "Collecting psutil>=5.0.0 (from wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/58/0eae6e4466e5abf779d7e2b71fac7fba5f59e00ea36ddb3ed690419ccb0f/psutil-5.4.8.tar.gz (422kB)\n",
            "\u001b[K    100% |████████████████████████████████| 430kB 4.7MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0 (from wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "Collecting GitPython>=1.0.0 (from wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "  Using cached https://files.pythonhosted.org/packages/fe/e5/fafe827507644c32d6dc553a1c435cdf882e0c28918a5bab29f7fbebfb70/GitPython-2.1.11-py2.py3-none-any.whl\n",
            "Collecting decorator>=4.3.0 (from networkx>=2.2->pyro-ppl->-r deep-learning-projects/requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/bb/a24838832ba35baf52f32ab1a49b906b5f82fb7c76b2f6a7e35e140bac30/decorator-4.3.0-py2.py3-none-any.whl\n",
            "Collecting certifi (from sentry-sdk>=0.4.0->wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/e0/accfc1b56b57e9750eba272e24c4dddeac86852c2bebd1236674d7887e8a/certifi-2018.11.29-py2.py3-none-any.whl (154kB)\n",
            "\u001b[K    100% |████████████████████████████████| 163kB 28.6MB/s \n",
            "\u001b[?25hCollecting urllib3 (from sentry-sdk>=0.4.0->wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl (118kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 29.8MB/s \n",
            "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests>=2.0.0->wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
            "\u001b[K    100% |████████████████████████████████| 143kB 29.2MB/s \n",
            "\u001b[?25hCollecting idna<2.9,>=2.5 (from requests>=2.0.0->wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 20.3MB/s \n",
            "\u001b[?25hCollecting PyYAML>=3.10 (from watchdog>=0.8.3->wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
            "\u001b[K    100% |████████████████████████████████| 276kB 4.6MB/s \n",
            "\u001b[?25hCollecting pathtools>=0.1.1 (from watchdog>=0.8.3->wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "Collecting argh>=0.24.1 (from watchdog>=0.8.3->wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "  Using cached https://files.pythonhosted.org/packages/06/1c/e667a7126f0b84aaa1c56844337bf0ac12445d1beb9c8a6199a7314944bf/argh-0.26.2-py2.py3-none-any.whl\n",
            "Collecting graphql-core>=0.5.0 (from gql>=0.1.0->wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "  Using cached https://files.pythonhosted.org/packages/35/dd/2dff553c929d059e53a95a8bcff66f6a3930d736dfea17f88d16229eaf84/graphql_core-2.1-py2.py3-none-any.whl\n",
            "Collecting promise>=0.4.0 (from gql>=0.1.0->wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/81/221d09d90176fd90aed4b530e31b8fedf207385767c06d1d46c550c5e418/promise-2.2.1.tar.gz\n",
            "Collecting gitdb2>=2.0.0 (from GitPython>=1.0.0->wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "  Using cached https://files.pythonhosted.org/packages/da/30/a407568aa8d8f25db817cf50121a958722f3fc5f87e3a6fba1f40c0633e3/gitdb2-2.0.5-py2.py3-none-any.whl\n",
            "Collecting rx>=1.6.0 (from graphql-core>=0.5.0->gql>=0.1.0->wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "  Using cached https://files.pythonhosted.org/packages/33/0f/5ef4ac78e2a538cc1b054eb86285fe0bf7a5dbaeaac2c584757c300515e2/Rx-1.6.1-py2.py3-none-any.whl\n",
            "Collecting smmap2>=2.0.0 (from gitdb2>=2.0.0->GitPython>=1.0.0->wandb->-r deep-learning-projects/requirements.txt (line 5))\n",
            "  Using cached https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: networkx, psutil, PyYAML, promise\n",
            "  Running setup.py bdist_wheel for networkx ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91\n",
            "  Running setup.py bdist_wheel for psutil ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d2/71/40/9c6993129f8cda369d0f21c46a13a6adab7fb1664fe6512551\n",
            "  Running setup.py bdist_wheel for PyYAML ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f\n",
            "  Running setup.py bdist_wheel for promise ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/92/84/9f/75e2235effae0e1c5a5c0626a503e532bbffcb7e79e672b606\n",
            "Successfully built networkx psutil PyYAML promise\n",
            "\u001b[31mkaggle 1.5.1.1 has requirement urllib3<1.23.0,>=1.15, but you'll have urllib3 1.24.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 0.0.1a1 has requirement requests~=2.18.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 0.0.1a1 has requirement six~=1.11.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, numpy, pillow, six, torchvision, torchsummary, tqdm, contextlib2, opt-einsum, decorator, networkx, graphviz, pyro-ppl, certifi, urllib3, sentry-sdk, chardet, idna, requests, PyYAML, pathtools, argh, watchdog, python-dateutil, subprocess32, Click, nvidia-ml-py3, promise, rx, graphql-core, gql, psutil, shortuuid, smmap2, gitdb2, GitPython, wandb\n",
            "  Found existing installation: torch 1.0.0\n",
            "    Uninstalling torch-1.0.0:\n",
            "      Successfully uninstalled torch-1.0.0\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "  Found existing installation: six 1.11.0\n",
            "    Uninstalling six-1.11.0:\n",
            "      Successfully uninstalled six-1.11.0\n",
            "  Found existing installation: torchvision 0.2.1\n",
            "    Uninstalling torchvision-0.2.1:\n",
            "      Successfully uninstalled torchvision-0.2.1\n",
            "  Found existing installation: torchsummary 1.5.1\n",
            "    Uninstalling torchsummary-1.5.1:\n",
            "      Successfully uninstalled torchsummary-1.5.1\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Can't uninstall 'tqdm'. No files were found to uninstall.\n",
            "  Running setup.py develop for tqdm\n",
            "\u001b[31mOperation cancelled by user\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w0oPov4hdzO-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Slsev5DP3zlB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sys.path.extend(('./deep-learning-projects', './src/tqdm'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DLVtUTdFVwur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "964feab5-bebc-46b8-afb7-109fb0312ebf"
      },
      "cell_type": "code",
      "source": [
        "for i in tqdm.tnrange(10):\n",
        "    time.sleep(0.1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./src/tqdm/tqdm/_tqdm_notebook.py:88: TqdmExperimentalWarning: Detect Google Colab 0.0.1a2 and thus load dummy ipywidgets package. Note that UI is different from that in Jupyter. See https://github.com/tqdm/tqdm/pull/640\n",
            "  \" See https://github.com/tqdm/tqdm/pull/640\".format(colab.__version__), TqdmExperimentalWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='10' value='10'></progress>100% 10/10 [00:01&lt;00:00,  9.58it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RDjqrJxmWaDP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "outputId": "327fb8a1-1900-424d-add3-66f6e9c2c85c"
      },
      "cell_type": "code",
      "source": [
        "normalized_train_dataset, train_dataloader, normalized_test_dataset, test_dataloader = dataset.create_normalized_datasets()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4b9f8df3ca61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnormalized_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_test_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_normalized_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/deep-learning-projects/projects/metalearning/dataset.py\u001b[0m in \u001b[0;36mcreate_normalized_datasets\u001b[0;34m(dataset_path, batch_size, num_workers, pin_memory, downsample_size, test_train_split_index, shuffle)\u001b[0m\n\u001b[1;32m    109\u001b[0m     unnormalized_train_dataset = MetaLearningH5DatasetFromDescription(dataset_path,  # META_LEARNING_DATA_SMALL,\n\u001b[1;32m    110\u001b[0m                                                                       \u001b[0munnormalized_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                                                                       end_index=test_train_split_index)\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     transformed_images = np.stack([unnormalized_transformer(image).numpy() for image in\n",
            "\u001b[0;32m/content/deep-learning-projects/projects/metalearning/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_file, transform, start_index, end_index, query_subset, num_dimensions, features_per_dimension)\u001b[0m\n\u001b[1;32m     66\u001b[0m                  num_dimensions=2, features_per_dimension=(10, 11)):\n\u001b[1;32m     67\u001b[0m         super(MetaLearningH5DatasetFromDescription, self).__init__(\n\u001b[0;32m---> 68\u001b[0;31m             in_file, transform, start_index, end_index, query_subset)\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-projects/projects/metalearning/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_file, transform, start_index, end_index, query_subset)\u001b[0m\n\u001b[1;32m     19\u001b[0m                  end_index=None, query_subset=None):\n\u001b[1;32m     20\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetaLearningH5Dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'drive/Research Projects/Meta-Learning/v1/CLEVR_meta_learning_uint8_desc.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jPiFEyGSbZ27",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from deep_learning_projects import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FpHzITaAbeXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "f519255c-3e4d-46eb-d6dd-cb2cbe4c8be7"
      },
      "cell_type": "code",
      "source": [
        "!ls -la ./src/tqdm"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 156\n",
            "drwxr-xr-x 9 root root  4096 Dec 29 21:11 .\n",
            "drwxr-xr-x 3 root root  4096 Dec 29 21:11 ..\n",
            "-rw-r--r-- 1 root root  1064 Dec 29 21:11 asv.conf.json\n",
            "drwxr-xr-x 2 root root  4096 Dec 29 21:11 benchmarks\n",
            "-rw-r--r-- 1 root root   127 Dec 29 21:11 codecov.yml\n",
            "-rw-r--r-- 1 root root  8091 Dec 29 21:11 CONTRIBUTING.md\n",
            "-rw-r--r-- 1 root root   151 Dec 29 21:11 .coveragerc\n",
            "drwxr-xr-x 2 root root  4096 Dec 29 21:11 examples\n",
            "drwxr-xr-x 8 root root  4096 Dec 29 21:24 .git\n",
            "-rw-r--r-- 1 root root   336 Dec 29 21:11 .gitattributes\n",
            "drwxr-xr-x 2 root root  4096 Dec 29 21:11 .github\n",
            "-rw-r--r-- 1 root root   268 Dec 29 21:11 .gitignore\n",
            "drwxr-xr-x 2 root root  4096 Dec 29 21:11 images\n",
            "-rw-r--r-- 1 root root  2003 Dec 29 21:11 LICENCE\n",
            "-rw-r--r-- 1 root root 10215 Dec 29 21:11 logo.png\n",
            "-rw-r--r-- 1 root root   657 Dec 29 21:11 .mailmap\n",
            "-rw-r--r-- 1 root root  3299 Dec 29 21:11 Makefile\n",
            "-rw-r--r-- 1 root root   378 Dec 29 21:11 MANIFEST.in\n",
            "-rw-r--r-- 1 root root 31827 Dec 29 21:11 README.rst\n",
            "-rw-r--r-- 1 root root    28 Dec 29 21:11 setup.cfg\n",
            "-rwxr-xr-x 1 root root  9275 Dec 29 21:11 setup.py\n",
            "-rw-r--r-- 1 root root   285 Dec 29 21:11 .style.yapf\n",
            "-rw-r--r-- 1 root root  1913 Dec 29 21:11 tox.ini\n",
            "drwxr-xr-x 5 root root  4096 Dec 29 21:11 tqdm\n",
            "-rw-r--r-- 1 root root   700 Dec 29 21:11 .tqdm.1.md\n",
            "drwxr-xr-x 2 root root  4096 Dec 29 21:24 tqdm.egg-info\n",
            "-rw-r--r-- 1 root root  1214 Dec 29 21:11 .travis.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rCamtWlQbmGo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fqKdkofz8Tqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "3a31751e-1c16-4464-cdd7-b77fb6c4d35e"
      },
      "cell_type": "code",
      "source": [
        "sys.path"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "vYQ9D13n8Uf2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27379433-7716-47cc-db5f-312f132921e2"
      },
      "cell_type": "code",
      "source": [
        "!ls -la /usr/local/lib/python3.6/dist-packages/tqdm*"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root staff 19 Dec 29 21:24 /usr/local/lib/python3.6/dist-packages/tqdm.egg-link\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C2ojtYFB8XXG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5edf7710-726c-495e-977e-20d86e796b1c"
      },
      "cell_type": "code",
      "source": [
        "!cat /usr/local/lib/python3.6/dist-packages/tqdm.egg-link"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/src/tqdm\n",
            "."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q0MHssn984PB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24c17b97-6673-43cd-9ff2-fd4c2c04ed2b"
      },
      "cell_type": "code",
      "source": [
        "!chmod -R 666 /content/src/projects \n",
        "!ls -la /content/src/projects/requirements.txt\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-rw-rw- 1 root root 102 Dec 28 18:04 /content/src/projects/requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SwdBpH9CA3nF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1314a75f-114d-4e04-cd4a-2a7c7786460a"
      },
      "cell_type": "code",
      "source": [
        "!chmod --help"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Usage: chmod [OPTION]... MODE[,MODE]... FILE...\n",
            "  or:  chmod [OPTION]... OCTAL-MODE FILE...\n",
            "  or:  chmod [OPTION]... --reference=RFILE FILE...\n",
            "Change the mode of each FILE to MODE.\n",
            "With --reference, change the mode of each FILE to that of RFILE.\n",
            "\n",
            "  -c, --changes          like verbose but report only when a change is made\n",
            "  -f, --silent, --quiet  suppress most error messages\n",
            "  -v, --verbose          output a diagnostic for every file processed\n",
            "      --no-preserve-root  do not treat '/' specially (the default)\n",
            "      --preserve-root    fail to operate recursively on '/'\n",
            "      --reference=RFILE  use RFILE's mode instead of MODE values\n",
            "  -R, --recursive        change files and directories recursively\n",
            "      --help     display this help and exit\n",
            "      --version  output version information and exit\n",
            "\n",
            "Each MODE is of the form '[ugoa]*([-+=]([rwxXst]*|[ugo]))+|[-+=][0-7]+'.\n",
            "\n",
            "GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
            "Full documentation at: <http://www.gnu.org/software/coreutils/chmod>\n",
            "or available locally via: info '(coreutils) chmod invocation'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pfv7Mig689rx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torchsummary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hlvVI-8X9PJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7a2569fc-6cc9-4152-fd95-6efcf0275519"
      },
      "cell_type": "code",
      "source": [
        "import projects.metalearning"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1c7f4428a5aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mprojects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetalearning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'projects'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-GZLWo7H9ePN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "b9f5ccb1-d945-46ed-d08b-0c0fce177a8f"
      },
      "cell_type": "code",
      "source": [
        "import projects"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2d563a3d4b83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mprojects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'projects'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6qNjhnHL_6dT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}