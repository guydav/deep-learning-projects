{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/guydavidson/.netrc\n",
      "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!wandb login 9676e3cc95066e4865586082971f2653245f09b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.special import factorial\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "from matplotlib import path as mpath\n",
    "\n",
    "import pickle\n",
    "import tabulate\n",
    "import wandb\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "\n",
    "import meta_learning_data_analysis as analysis\n",
    "import meta_learning_analysis_plots as plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['six_replications_analyses', 'control_analyses', 'query_mod_replications', 'six_replications_updated_analyses', 'updated_control_analyses', 'query_mod_updated_analyses', 'forgetting_curves_raw_data', 'preliminary_maml_analyses', 'baseline_maml_comparison_analyses', 'maml_analyses', 'maml_alpha_0_analyses', 'maml_meta_test_analyses', 'balanced_batches_analyses', 'baseline_total_curve_analyses', 'control_total_curve_analyses', 'query_mod_total_curve_analyses', 'simultaneous_training_analyses', 'per_task_simultaneous_training_analyses', 'task_conditional_analyses', 'task_conditional_multiplicative_only_analyses', 'task_conditional_additive_only_analyses'])\n"
     ]
    }
   ],
   "source": [
    "cache = analysis.refresh_cache()\n",
    "print(cache.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "# Baseline analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'six_replications_analyses' in cache:\n",
    "    six_replications_analyses = cache['six_replications_analyses']\n",
    "\n",
    "else:\n",
    "    six_replications_by_dimension_runs = analysis.load_runs(60)\n",
    "    print('Loaded runs')\n",
    "\n",
    "    six_reps_dict = {dimension_name:analysis.process_multiple_runs(run_set) \n",
    "                     for run_set, dimension_name \n",
    "                     in zip(six_replications_by_dimension_runs, analysis.CONDITION_ANALYSES_FIELDS)}\n",
    "    six_replications_analyses = analysis.ConditionAnalysesSet(**six_reps_dict)\n",
    "\n",
    "    cache = analysis.refresh_cache(dict(six_replications_analyses=six_replications_analyses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'six_replications_updated_analyses' in cache:\n",
    "#     six_replications_updated_analyses = cache['six_replications_updated_analyses']\n",
    "\n",
    "# else:\n",
    "six_replications_by_dimension_runs = analysis.load_runs(60)\n",
    "print('Loaded runs')\n",
    "\n",
    "# note: the equal accuracy field will come in as accuracy_drops\n",
    "updated_six_reps_dict = {}\n",
    "start_index = 0\n",
    "for run_set, dimension_name in zip(six_replications_by_dimension_runs[start_index:], \n",
    "                                   analysis.CONDITION_ANALYSES_FIELDS[start_index:]):\n",
    "    updated_six_reps_dict[dimension_name] = analysis.process_multiple_runs(\n",
    "        run_set, parse_func=analysis.parse_run_results_with_new_task_accuracy_and_equal_size) \n",
    "\n",
    "# combined_analysis = analysis.process_multiple_runs(\n",
    "#     six_replications_by_dimension_runs[3], \n",
    "#     parse_func=analysis.parse_run_results_with_new_task_accuracy_and_equal_size)\n",
    "\n",
    "six_replications_updated_analyses = analysis.ConditionAnalysesSet(**updated_six_reps_dict)\n",
    "\n",
    "cache = analysis.refresh_cache(dict(six_replications_updated_analyses=six_replications_updated_analyses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'baseline_total_curve_analyses' in cache:\n",
    "#     baseline_total_curve_analyses = cache['baseline_total_curve_analyses']\n",
    "\n",
    "# else:\n",
    "six_replications_by_dimension_runs = analysis.load_runs(60)\n",
    "print('Loaded runs')\n",
    "\n",
    "analyses_per_dimension = {}\n",
    "\n",
    "for run_set, dimension_name in zip(six_replications_by_dimension_runs, analysis.CONDITION_ANALYSES_FIELDS):\n",
    "    print(f'Starting {dimension_name}')\n",
    "    total_curve_raw, total_curve_mean, total_curve_std, total_curve_sem = \\\n",
    "        analysis.process_multiple_runs_total_task_training_curves(run_set)\n",
    "\n",
    "    analyses_per_dimension[dimension_name] = analysis.TotalCurveResults(raw=total_curve_raw,\n",
    "                                                                        mean=total_curve_mean, \n",
    "                                                                        std=total_curve_std, \n",
    "                                                                        sem=total_curve_sem)\n",
    "\n",
    "total_curve_analyses = analysis.ConditionAnalysesSet(**analyses_per_dimension)\n",
    "cache = analysis.refresh_cache(dict(baseline_total_curve_analyses=total_curve_analyses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "# Control analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'control_analyses' in cache:\n",
    "    control_analyses = cache['control_analyses']\n",
    "\n",
    "else:\n",
    "    control_runs = analysis.load_runs(150, 'meta-learning-scaling/sequential-benchmark-control', False)\n",
    "    print(f'Loaded runs')\n",
    "    control_analyses = analysis.ConditionAnalysesSet(combined=analysis.process_multiple_runs(control_runs.combined))\n",
    "\n",
    "    cache = analysis.refresh_cache(dict(control_analyses=control_analyses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'six_replications_updated_analyses' in cache:\n",
    "#     six_replications_updated_analyses = cache['six_replications_updated_analyses']\n",
    "\n",
    "# else:\n",
    "control_runs = analysis.load_runs(150, 'meta-learning-scaling/sequential-benchmark-control', False)\n",
    "print('Loaded runs')\n",
    "\n",
    "updated_control_analyses = analysis.ConditionAnalysesSet(\n",
    "    combined=analysis.process_multiple_runs(control_runs.combined, \n",
    "                                            parse_func=analysis.parse_run_results_with_new_task_accuracy_and_equal_size))\n",
    "\n",
    "\n",
    "cache = analysis.refresh_cache(dict(updated_control_analyses=updated_control_analyses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'control_total_curve_analyses' in cache:\n",
    "    control_total_curve_analyses = cache['control_total_curve_analyses']\n",
    "\n",
    "else:\n",
    "    control_runs = analysis.load_runs(150, 'meta-learning-scaling/sequential-benchmark-control', False)\n",
    "    print('Loaded runs')\n",
    "    \n",
    "    total_curve_raw, total_curve_mean, total_curve_std, total_curve_sem = \\\n",
    "            analysis.process_multiple_runs_total_task_training_curves(control_runs.combined)\n",
    "    \n",
    "    control_total_curve_analyses = analysis.ConditionAnalysesSet(\n",
    "        combined=analysis.TotalCurveResults(raw=total_curve_raw,\n",
    "                                            mean=total_curve_mean,\n",
    "                                            std=total_curve_std,\n",
    "                                            sem=total_curve_sem))\n",
    "\n",
    "    cache = analysis.refresh_cache(dict(control_total_curve_analyses=control_total_curve_analyses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = analysis.refresh_cache(dict(control_analyses=control_analyses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the number of examples by dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = (1000, 520000)\n",
    "\n",
    "plots.plot_processed_results(first_replication_analyses.color.examples, 'Color 10-run average', ylim)\n",
    "plots.plot_processed_results(first_replication_analyses.shape.examples, 'Shape 10-run average', ylim)\n",
    "plots.plot_processed_results(first_replication_analyses.texture.examples, 'Material 10-run average', ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = (1000, 700000)\n",
    "\n",
    "plots.plot_processed_results(six_replications_analyses.color.examples, 'Color 60-run average', ylim)\n",
    "plots.plot_processed_results(six_replications_analyses.shape.examples, 'Shape 60-run average', ylim)\n",
    "plots.plot_processed_results(six_replications_analyses.texture.examples, 'Material 60-run average', ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the log of the number of examples to criterion, in each dimension, with error bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the combined results over all 180 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = (7.75, 13.25)\n",
    "\n",
    "plots.plot_processed_results(six_replications_analyses.combined.log_examples, 'Combined 180-run average', \n",
    "                       ylim, log_x=(True, True), log_y=True, sem_n=180, shade_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the absolute accuracy after introducing a new task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = None\n",
    "\n",
    "plots.plot_processed_results(six_replications_analyses.color.accuracies, 'Color 60-run average', \n",
    "                       ylim, log_x=False, log_y=False, sem_n=60, shade_error=True)\n",
    "plots.plot_processed_results(six_replications_analyses.shape.accuracies, 'Shape 60-run average', \n",
    "                       ylim, log_x=False, log_y=False, sem_n=60, shade_error=True)\n",
    "plots.plot_processed_results(six_replications_analyses.texture.accuracies, 'Material 60-run average', \n",
    "                       ylim, log_x=False, log_y=False, sem_n=60, shade_error=True)\n",
    "plots.plot_processed_results(six_replications_analyses.combined.accuracies, 'Combined 180-run average', \n",
    "                       ylim, log_x=False, log_y=False, sem_n=180, shade_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the accuracy drop after introducing a new task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = None\n",
    "\n",
    "plots.plot_processed_results(six_replications_analyses.color.accuracy_drops, 'Color 60-run average', \n",
    "                       ylim, log_x=False, log_y=False, sem_n=60, shade_error=True)\n",
    "plots.plot_processed_results(six_replications_analyses.shape.accuracy_drops, 'Shape 60-run average', \n",
    "                       ylim, log_x=False, log_y=False, sem_n=60, shade_error=True)\n",
    "plots.plot_processed_results(six_replications_analyses.texture.accuracy_drops, 'Material 60-run average', \n",
    "                       ylim, log_x=False, log_y=False, sem_n=60, shade_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "# Query-modulated analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'query_mod_replications' in cache:\n",
    "    query_mod_replications = cache['query_mod_replications']\n",
    "\n",
    "else:\n",
    "    query_mod_runs = analysis.query_modulated_runs_by_dimension(30)\n",
    "    query_mod_replications = {}\n",
    "\n",
    "    ignore_runs = [] # ('at6pkicv', )\n",
    "    for mod_level in query_mod_runs:\n",
    "        mod_level_runs = query_mod_runs[mod_level]\n",
    "\n",
    "        mod_level_dict = {dimension_name: analysis.process_multiple_runs(mod_level_runs[i], ignore_runs=ignore_runs) \n",
    "                          for i, dimension_name \n",
    "                          in enumerate(analysis.CONDITION_ANALYSES_FIELDS)}\n",
    "\n",
    "        query_mod_replications[mod_level] = analysis.ConditionAnalysesSet(**mod_level_dict)\n",
    "\n",
    "    cache = analysis.refresh_cache(dict(query_mod_replications=query_mod_replications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = analysis.refresh_cache(dict(query_mod_updated_analyses=query_mod_replications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'six_replications_updated_analyses' in cache:\n",
    "#     six_replications_updated_analyses = cache['six_replications_updated_analyses']\n",
    "\n",
    "# else:\n",
    "query_mod_runs = analysis.query_modulated_runs_by_dimension(30)\n",
    "print('Loaded runs')\n",
    "\n",
    "# note: the equal accuracy field will come in as accuracy_drops\n",
    "query_mod_replications = {}\n",
    "mod_levels = list(query_mod_runs.keys())\n",
    "start_index = 0\n",
    "\n",
    "for mod_level in mod_levels[start_index:]:\n",
    "    print(f'Starting mod level {mod_level}')\n",
    "    mod_level_runs = query_mod_runs[mod_level]\n",
    "\n",
    "    mod_level_dict = {dimension_name: analysis.process_multiple_runs(mod_level_runs[i], \n",
    "                                                                     parse_func=analysis.parse_run_results_with_new_task_accuracy_and_equal_size) \n",
    "                      for i, dimension_name \n",
    "                      in enumerate(analysis.CONDITION_ANALYSES_FIELDS)}\n",
    "\n",
    "    query_mod_replications[mod_level] = analysis.ConditionAnalysesSet(**mod_level_dict)\n",
    "\n",
    "\n",
    "cache = analysis.refresh_cache(dict(query_mod_updated_analyses=query_mod_replications))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = analysis.refresh_cache(dict(query_mod_replications=query_mod_replications,\n",
    "                                    control_analyses=control_analyses,\n",
    "                                    six_replications_analyses=six_replications_analyses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'query_mod_total_curve_analyses' in cache:\n",
    "    query_mod_total_curve_analyses = cache['query_mod_total_curve_analyses']\n",
    "\n",
    "else:\n",
    "    query_mod_runs = analysis.query_modulated_runs_by_dimension(30)\n",
    "    print('Loaded runs')\n",
    "    \n",
    "    query_mod_total_curve_analyses = {}\n",
    "    mod_levels = list(query_mod_runs.keys())\n",
    "    start_index = 0\n",
    "    \n",
    "    for mod_level in mod_levels[start_index:]:\n",
    "        print(f'Starting mod level {mod_level}')\n",
    "        mod_level_runs = query_mod_runs[mod_level]\n",
    "\n",
    "        analyses_per_dimension = {}\n",
    "        \n",
    "        for run_set, dimension_name in zip(mod_level_runs, analysis.CONDITION_ANALYSES_FIELDS):\n",
    "            print(f'Starting {dimension_name}')\n",
    "            total_curve_raw, total_curve_mean, total_curve_std, total_curve_sem = \\\n",
    "                analysis.process_multiple_runs_total_task_training_curves(run_set)\n",
    "\n",
    "            analyses_per_dimension[dimension_name] = analysis.TotalCurveResults(raw=total_curve_raw,\n",
    "                                                                                mean=total_curve_mean, \n",
    "                                                                                std=total_curve_std, \n",
    "                                                                                sem=total_curve_sem)\n",
    "\n",
    "        query_mod_total_curve_analyses[mod_level] = analysis.ConditionAnalysesSet(**analyses_per_dimension)\n",
    "            \n",
    "    cache = analysis.refresh_cache(dict(query_mod_total_curve_analyses=query_mod_total_curve_analyses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_mod_total_curve_analyses.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "# MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'maml_analyses' in cache:\n",
    "    maml_analyses = cache['maml_analyses']\n",
    "\n",
    "else:\n",
    "    maml_runs = analysis.load_runs(30, 'meta-learning-scaling/maml-sequential-benchmark')\n",
    "    print('Loaded runs')\n",
    "\n",
    "    # ignore_runs = set(['oz996ztv', 'oin8pqu2', 'h09i9xyg', 'umo8x16f', 'pm76ui1s', \n",
    "    #                    'qnyo08x8', 'hmjtjheq', 'wki7q8cs', 'q8ku840y'])\n",
    "    ignore_runs = set()\n",
    "\n",
    "    maml_analyses_dict = {}\n",
    "    start_index = 0\n",
    "    for run_set, dimension_name in zip(maml_runs[start_index:], \n",
    "                                       analysis.CONDITION_ANALYSES_FIELDS[start_index:]):\n",
    "\n",
    "        maml_analyses_dict[dimension_name] = analysis.process_multiple_runs(\n",
    "            run_set, parse_func=analysis.parse_run_results_with_new_task_accuracy_and_equal_size,\n",
    "            ignore_runs=ignore_runs) \n",
    "\n",
    "    maml_analyses = analysis.ConditionAnalysesSet(**maml_analyses_dict)\n",
    "    cache = analysis.refresh_cache(dict(maml_analyses=maml_analyses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'six_replications_updated_analyses' in cache:\n",
    "#     six_replications_updated_analyses = cache['six_replications_updated_analyses']\n",
    "\n",
    "# else:\n",
    "maml_alpha_0_runs = analysis.load_runs(20, 'meta-learning-scaling/maml-alpha-0')\n",
    "print('Loaded runs')\n",
    "\n",
    "raise ValueError('This will not work yeet')\n",
    "\n",
    "# ignore_runs = set(['ac82mceh', '7kau3ypy', 'g9ujw7gg', 'avmcbnot'])\n",
    "ignore_runs = set()\n",
    "\n",
    "maml_alpha_0_analyses_dict = {}\n",
    "start_index = 0\n",
    "for run_set, dimension_name in zip(maml_alpha_0_runs[start_index:], \n",
    "                                   analysis.CONDITION_ANALYSES_FIELDS[start_index:]):\n",
    "    \n",
    "    maml_alpha_0_analyses_dict[dimension_name] = analysis.process_multiple_runs(\n",
    "        run_set, parse_func=analysis.parse_run_results_with_new_task_accuracy_and_equal_size,\n",
    "        ignore_runs=ignore_runs) \n",
    "\n",
    "maml_alpha_0_analyses = analysis.ConditionAnalysesSet(**maml_alpha_0_analyses_dict)\n",
    "cache = analysis.refresh_cache(dict(maml_alpha_0_analyses=maml_alpha_0_analyses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'maml_meta_test_analyses' in cache:\n",
    "    maml_meta_test_analyses = cache['maml_meta_test_analyses']\n",
    "\n",
    "else:\n",
    "    maml_meta_test_runs = analysis.load_runs(30, 'meta-learning-scaling/maml-meta-test')\n",
    "    print('Loaded runs')\n",
    "\n",
    "    # ignore_runs = set(['u3gk9oio'])\n",
    "    ignore_runs = set()\n",
    "\n",
    "    maml_meta_test_analyses_dict = {}\n",
    "    start_index = 0\n",
    "    for run_set, dimension_name in zip(maml_meta_test_runs[start_index:], \n",
    "                                       analysis.CONDITION_ANALYSES_FIELDS[start_index:]):\n",
    "\n",
    "        maml_meta_test_analyses_dict[dimension_name] = analysis.process_multiple_runs(\n",
    "            run_set, parse_func=analysis.parse_run_results_with_new_task_accuracy_and_equal_size,\n",
    "            ignore_runs=ignore_runs) \n",
    "\n",
    "    maml_meta_test_analyses = analysis.ConditionAnalysesSet(**maml_meta_test_analyses_dict)\n",
    "    cache = analysis.refresh_cache(dict(maml_meta_test_analyses=maml_meta_test_analyses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'balanced_batches_analyses' in cache:\n",
    "    balanced_batches_analyses = cache['balanced_batches_analyses']\n",
    "\n",
    "else:\n",
    "    balanced_batches_runs = analysis.load_runs(30, 'meta-learning-scaling/balanced-batches-sequential-benchmark')\n",
    "    print('Loaded runs')\n",
    "\n",
    "    # ignore_runs = set(['u3gk9oio'])\n",
    "    ignore_runs = set()\n",
    "\n",
    "    balanced_batches_analyses_dict = {}\n",
    "    start_index = 0\n",
    "    for run_set, dimension_name in zip(balanced_batches_runs[start_index:], \n",
    "                                       analysis.CONDITION_ANALYSES_FIELDS[start_index:]):\n",
    "\n",
    "        balanced_batches_analyses_dict[dimension_name] = analysis.process_multiple_runs(\n",
    "            run_set, parse_func=analysis.parse_run_results_with_new_task_accuracy_and_equal_size,\n",
    "            ignore_runs=ignore_runs) \n",
    "\n",
    "    balanced_batches_analyses = analysis.ConditionAnalysesSet(**balanced_batches_analyses_dict)\n",
    "    cache = analysis.refresh_cache(dict(balanced_batches_analyses=balanced_batches_analyses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_comparison_run_ids = [1000, 1001, 2000, 2001, 2002, \n",
    "                           2003, 2004, 2005, 2006, 2007, \n",
    "                           2008, 2009, 3000, 3001, 3002, \n",
    "                           3003, 3004, 3005, 3006, 3007, 3008]\n",
    "\n",
    "maml_comparison_runs = analysis.load_runs(10, split_runs_by_dimension=False, valid_run_ids=set(maml_comparison_run_ids))\n",
    "print('Loaded runs')\n",
    "\n",
    "baseline_maml_comparison_analyses = analysis.ConditionAnalysesSet(\n",
    "    combined=analysis.process_multiple_runs(maml_comparison_runs.combined, \n",
    "                                            parse_func=analysis.parse_run_results_with_new_task_accuracy_and_equal_size,))\n",
    "\n",
    "\n",
    "cache = analysis.refresh_cache(dict(baseline_maml_comparison_analyses=baseline_maml_comparison_analyses))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Simultaneous training in a dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'simultaneous_training_analyses' in cache:\n",
    "#     simultaneous_training_analyses = cache['simultaneous_training_analyses']\n",
    "\n",
    "# else:\n",
    "simultaneous_training_runs = analysis.load_runs(20, 'meta-learning-scaling/simultaneous-training')\n",
    "print('Loaded runs')\n",
    "\n",
    "# ignore_runs = set(['u3gk9oio'])\n",
    "ignore_runs = set()\n",
    "\n",
    "simultaneous_training_analyses_dict = {}\n",
    "per_task_simultaneous_training_analyses_dict = {}\n",
    "start_index = 0\n",
    "for run_set, dimension_name in zip(simultaneous_training_runs[start_index:], \n",
    "                                   analysis.CONDITION_ANALYSES_FIELDS[start_index:]):\n",
    "\n",
    "    stacked_results, all_results_mean, all_results_std, all_results_sem, per_task_results_mean, per_task_results_std, per_task_results_sem = analysis.process_multiple_runs_simultaneous_training(run_set, ignore_runs=ignore_runs)\n",
    "\n",
    "    simultaneous_training_analyses_dict[dimension_name] = analysis.TotalCurveResults(raw=stacked_results,\n",
    "                                                                                     mean=all_results_mean, \n",
    "                                                                                     std=all_results_std, \n",
    "                                                                                     sem=all_results_sem)\n",
    "\n",
    "    per_task_simultaneous_training_analyses_dict[dimension_name] = analysis.TotalCurveResults(raw=stacked_results,\n",
    "                                                                                              mean=per_task_results_mean, \n",
    "                                                                                              std=per_task_results_std, \n",
    "                                                                                              sem=per_task_results_sem)\n",
    "\n",
    "simultaneous_training_analyses = analysis.ConditionAnalysesSet(**simultaneous_training_analyses_dict)\n",
    "per_task_simultaneous_training_analyses = analysis.ConditionAnalysesSet(**per_task_simultaneous_training_analyses_dict)\n",
    "cache = analysis.refresh_cache(dict(simultaneous_training_analyses=simultaneous_training_analyses,\n",
    "                                    per_task_simultaneous_training_analyses=per_task_simultaneous_training_analyses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# New Task Modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'task_conditional_analyses' in cache:\n",
    "    task_conditional_analyses = cache['task_conditional_analyses']\n",
    "\n",
    "else:\n",
    "    task_modulated_runs = analysis.load_runs(20, 'meta-learning-scaling/task-conditional-all-layers')\n",
    "    print('Loaded runs')\n",
    "\n",
    "    # ignore_runs = set(['u3gk9oio'])\n",
    "    # ignore_runs = set(['Task-conditional-[0, 1, 2, 3]-1017'])\n",
    "    ignore_runs = set()\n",
    "\n",
    "    task_modulated_analyses_dict = {}\n",
    "    start_index = 0\n",
    "    for run_set, dimension_name in zip(task_modulated_runs[start_index:], \n",
    "                                       analysis.CONDITION_ANALYSES_FIELDS[start_index:]):\n",
    "\n",
    "        task_modulated_analyses_dict[dimension_name] = analysis.process_multiple_runs(\n",
    "            run_set, parse_func=analysis.parse_run_results_with_new_task_accuracy_and_equal_size,\n",
    "            ignore_runs=ignore_runs) \n",
    "\n",
    "    task_conditional_analyses = analysis.ConditionAnalysesSet(**task_modulated_analyses_dict)\n",
    "    cache = analysis.refresh_cache(dict(task_conditional_analyses=task_conditional_analyses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'task_conditional_multiplicative_only_analyses' in cache:\n",
    "    task_conditional_multiplicative_only_analyses = cache['task_conditional_multiplicative_only_analyses']\n",
    "\n",
    "else:\n",
    "    task_modulated_runs = analysis.load_runs(20, 'meta-learning-scaling/task-conditional-all-layers-multiplicative-only')\n",
    "    print('Loaded runs')\n",
    "\n",
    "    # ignore_runs = set(['Task-conditional-multiplicative-[0, 1, 2, 3]-1006',\n",
    "    #                   'Task-conditional-multiplicative-[0, 1, 2, 3]-1005'])\n",
    "    ignore_runs = set()\n",
    "\n",
    "    task_modulated_analyses_dict = {}\n",
    "    start_index = 0\n",
    "    for run_set, dimension_name in zip(task_modulated_runs[start_index:], \n",
    "                                       analysis.CONDITION_ANALYSES_FIELDS[start_index:]):\n",
    "\n",
    "        task_modulated_analyses_dict[dimension_name] = analysis.process_multiple_runs(\n",
    "            run_set, parse_func=analysis.parse_run_results_with_new_task_accuracy_and_equal_size,\n",
    "            ignore_runs=ignore_runs) \n",
    "\n",
    "    task_conditional_multiplicative_only_analyses = analysis.ConditionAnalysesSet(**task_modulated_analyses_dict)\n",
    "    cache = analysis.refresh_cache(dict(task_conditional_multiplicative_only_analyses=task_conditional_multiplicative_only_analyses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'task_conditional_additive_only_analyses' in cache:\n",
    "    task_conditional_additive_only_analyses = cache['task_conditional_additive_only_analyses']\n",
    "\n",
    "else:\n",
    "    task_modulated_runs = analyses_caches/alysis.load_runs(20, 'meta-learning-scaling/task-conditional-all-layers-additive-only')\n",
    "    print('Loaded runs')\n",
    "\n",
    "    # ignore_runs = set(['u3gk9oio'])\n",
    "    ignore_runs = set()\n",
    "\n",
    "    task_modulated_analyses_dict = {}\n",
    "    start_index = 0\n",
    "    for run_set, dimension_name in zip(task_modulated_runs[start_index:], \n",
    "                                       analysis.CONDITION_ANALYSES_FIELDS[start_index:]):\n",
    "\n",
    "        task_modulated_analyses_dict[dimension_name] = analysis.process_multiple_runs(\n",
    "            run_set, parse_func=analysis.parse_run_results_with_new_task_accuracy_and_equal_size,\n",
    "            ignore_runs=ignore_runs) \n",
    "\n",
    "    task_conditional_additive_only_analyses = analysis.ConditionAnalysesSet(**task_modulated_analyses_dict)\n",
    "    cache = analysis.refresh_cache(dict(task_conditional_additive_only_analyses=task_conditional_additive_only_analyses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the task-conditional weights en masse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded runs\n",
      "Task-conditional-[0, 1, 2, 3]-1017\n",
      "Task-conditional-[0, 1, 2, 3]-1019\n",
      "Task-conditional-[0, 1, 2, 3]-1018\n",
      "Task-conditional-[0, 1, 2, 3]-1009\n",
      "Task-conditional-[0, 1, 2, 3]-1008\n",
      "Task-conditional-[0, 1, 2, 3]-1007\n",
      "Task-conditional-[0, 1, 2, 3]-1006\n",
      "Task-conditional-[0, 1, 2, 3]-1016\n",
      "Task-conditional-[0, 1, 2, 3]-1015\n",
      "Task-conditional-[0, 1, 2, 3]-3009 10\n",
      "Task-conditional-[0, 1, 2, 3]-3019\n",
      "Task-conditional-[0, 1, 2, 3]-1014\n",
      "Task-conditional-[0, 1, 2, 3]-3018\n",
      "Task-conditional-[0, 1, 2, 3]-3008\n",
      "Task-conditional-[0, 1, 2, 3]-3017\n",
      "Task-conditional-[0, 1, 2, 3]-1005\n",
      "Task-conditional-[0, 1, 2, 3]-3007\n",
      "Task-conditional-[0, 1, 2, 3]-3016\n",
      "Task-conditional-[0, 1, 2, 3]-3006\n",
      "Task-conditional-[0, 1, 2, 3]-3015 20\n",
      "Task-conditional-[0, 1, 2, 3]-3005\n",
      "Task-conditional-[0, 1, 2, 3]-1004\n",
      "Task-conditional-[0, 1, 2, 3]-3014\n",
      "Task-conditional-[0, 1, 2, 3]-3004\n",
      "Task-conditional-[0, 1, 2, 3]-3013\n",
      "Task-conditional-[0, 1, 2, 3]-3003\n",
      "Task-conditional-[0, 1, 2, 3]-3012\n",
      "Task-conditional-[0, 1, 2, 3]-1003\n",
      "Task-conditional-[0, 1, 2, 3]-3002\n",
      "Task-conditional-[0, 1, 2, 3]-3001\n",
      "Task-conditional-[0, 1, 2, 3]-3011\n",
      "Task-conditional-[0, 1, 2, 3]-1012\n",
      "Task-conditional-[0, 1, 2, 3]-3010\n",
      "Task-conditional-[0, 1, 2, 3]-3000\n",
      "Task-conditional-[0, 1, 2, 3]-1002\n",
      "Task-conditional-[0, 1, 2, 3]-2009\n",
      "Task-conditional-[0, 1, 2, 3]-2019\n",
      "Task-conditional-[0, 1, 2, 3]-2018\n",
      "Task-conditional-[0, 1, 2, 3]-2017 40\n",
      "Task-conditional-[0, 1, 2, 3]-2008\n",
      "Task-conditional-[0, 1, 2, 3]-2016\n",
      "Task-conditional-[0, 1, 2, 3]-2007\n",
      "Task-conditional-[0, 1, 2, 3]-2015\n",
      "Task-conditional-[0, 1, 2, 3]-2006\n",
      "Task-conditional-[0, 1, 2, 3]-2014\n",
      "Task-conditional-[0, 1, 2, 3]-2005\n",
      "Task-conditional-[0, 1, 2, 3]-2013 50\n",
      "Task-conditional-[0, 1, 2, 3]-2004\n",
      "Task-conditional-[0, 1, 2, 3]-2003\n",
      "Task-conditional-[0, 1, 2, 3]-2012\n",
      "Task-conditional-[0, 1, 2, 3]-2002\n",
      "Task-conditional-[0, 1, 2, 3]-2011\n",
      "Task-conditional-[0, 1, 2, 3]-2001\n",
      "Task-conditional-[0, 1, 2, 3]-2000\n",
      "Task-conditional-[0, 1, 2, 3]-2010\n",
      "Task-conditional-[0, 1, 2, 3]-1010\n",
      "Task-conditional-[0, 1, 2, 3]-1000 60\n"
     ]
    }
   ],
   "source": [
    "if 'task_conditional_weights' in cache:\n",
    "    task_conditional_weights = cache['task_conditional_weights']\n",
    "\n",
    "else:\n",
    "    task_modulated_runs = analysis.load_runs(20, 'meta-learning-scaling/task-conditional-all-layers')\n",
    "    print('Loaded runs')\n",
    "\n",
    "    # ignore_runs = set(['u3gk9oio'])\n",
    "    ignore_runs = set(['Task-conditional-[0, 1, 2, 3]-1013',\n",
    "                      'Task-conditional-[0, 1, 2, 3]-1011',\n",
    "                      'Task-conditional-[0, 1, 2, 3]-1001'])\n",
    "#     ignore_runs = set()\n",
    "\n",
    "    task_conditional_weights = analysis.parse_task_conditional_weights(task_modulated_runs.combined,\n",
    "                                                                      additive=True,\n",
    "                                                                      multiplicative=True,\n",
    "                                                                      ignore_runs=ignore_runs)\n",
    "\n",
    "    cache = analysis.refresh_cache(dict(task_conditional_weights=task_conditional_weights))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded runs\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1005\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1006\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1009\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1008\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1007\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1019\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1018\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1017\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1016\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1015 10\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1014\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1004\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1003\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1013\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3009\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3019\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3008\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1012\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3018\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3007 20\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2019\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3017\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1002\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2018\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3006\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2017\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3016\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2009\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3005\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2016 30\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2008\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2015\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3015\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3004\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2014\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2007\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3014\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2006\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2013\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1001 40\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2005\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3003\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3013\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1011\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3002\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2004\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2012\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3012\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2003\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3001 50\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2002\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3011\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2011\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2001\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3000\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-3010\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2000\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-2010\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1010\n",
      "Task-conditional-multiplicative-[0, 1, 2, 3]-1000 60\n"
     ]
    }
   ],
   "source": [
    "if 'task_conditional_multiplicative_only_weights' in cache:\n",
    "    task_conditional_multiplicative_only_weights = cache['task_conditional_multiplicative_only_weights']\n",
    "\n",
    "else:\n",
    "    task_modulated_runs = analysis.load_runs(20, 'meta-learning-scaling/task-conditional-all-layers-multiplicative-only')\n",
    "    print('Loaded runs')\n",
    "\n",
    "    # ignore_runs = set(['Task-conditional-multiplicative-[0, 1, 2, 3]-1006',\n",
    "    #                   'Task-conditional-multiplicative-[0, 1, 2, 3]-1005'])\n",
    "    ignore_runs = set()\n",
    "\n",
    "    task_conditional_multiplicative_only_weights = analysis.parse_task_conditional_weights(task_modulated_runs.combined,\n",
    "                                                                      additive=False,\n",
    "                                                                      multiplicative=True,\n",
    "                                                                      ignore_runs=ignore_runs)\n",
    "\n",
    "    cache = analysis.refresh_cache(dict(task_conditional_multiplicative_only_weights=task_conditional_multiplicative_only_weights))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded runs\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3014\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3019\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3004\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3009\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3013\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3018\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3003\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3008\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3017\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3002 10\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3012\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3007\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1009\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3016\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3006\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3001\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3011\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3015\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3010\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3005 20\n",
      "Task-conditional-additive-[0, 1, 2, 3]-3000\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1008\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1019\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1007\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1014\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1004\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1018\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1013\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1003\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1012 30\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1002\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1006\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2019\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2009\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2008\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1017\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2018\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2007\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2017\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2006 40\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2016\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2005\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1016\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2015\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2004\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1011\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2014\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2003\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2013\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1001 50\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2002\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2012\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2011\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2001\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2010\n",
      "Task-conditional-additive-[0, 1, 2, 3]-2000\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1015\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1005\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1010\n",
      "Task-conditional-additive-[0, 1, 2, 3]-1000 60\n"
     ]
    }
   ],
   "source": [
    "if 'task_conditional_additive_only_weights' in cache:\n",
    "    task_conditional_additive_only_weights = cache['task_conditional_additive_only_weights']\n",
    "\n",
    "else:\n",
    "    task_modulated_runs = analysis.load_runs(20, 'meta-learning-scaling/task-conditional-all-layers-additive-only')\n",
    "    print('Loaded runs')\n",
    "\n",
    "    # ignore_runs = set(['u3gk9oio'])\n",
    "    ignore_runs = set()\n",
    "\n",
    "    task_conditional_additive_only_weights = analysis.parse_task_conditional_weights(task_modulated_runs.combined,\n",
    "                                                                      additive=True,\n",
    "                                                                      multiplicative=False,\n",
    "                                                                      ignore_runs=ignore_runs)\n",
    "\n",
    "    cache = analysis.refresh_cache(dict(task_conditional_additive_only_weights=task_conditional_additive_only_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing around with reading from the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../projects/')\n",
    "\n",
    "from metalearning import cnnmlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_LEARNING_RATE = 5e-4\n",
    "DEFAULT_WEIGHT_DECAY = 1e-4\n",
    "\n",
    "def create_task_conditional_model(multiplicative=True, additive=True, checkpoint_path=None, name=None):\n",
    "    mod_level = list(range(4))\n",
    "\n",
    "    model = cnnmlp.TaskConditionalCNNMLP(\n",
    "        mod_level=mod_level,\n",
    "        multiplicative_mod=multiplicative,\n",
    "        additive_mod=additive,\n",
    "        query_length=30,\n",
    "        conv_filter_sizes=(16, 32, 48, 64),\n",
    "        conv_output_size=4480,\n",
    "        mlp_layer_sizes=(512, 512, 512, 512),\n",
    "        lr=DEFAULT_LEARNING_RATE,\n",
    "        weight_decay=DEFAULT_WEIGHT_DECAY,\n",
    "        use_lr_scheduler=False,\n",
    "        conv_dropout=False,\n",
    "        mlp_dropout=False,\n",
    "        name=name)\n",
    "\n",
    "    if checkpoint_path is not None:\n",
    "        model.load_state(checkpoint_path)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task-conditional-additive-3014'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = api.run('meta-learning-scaling/task-conditional-all-layers-additive-only/runs/49dq79wf')\n",
    "last_checkpoint_file = run.file(f'{run.name.replace(\"[0, 1, 2, 3]-\", \"\")}-query-9.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = last_checkpoint_file.download(replace=True, root='/tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_task_conditional_model(multiplicative=False, \n",
    "                                      checkpoint_path='/tmp/' + last_checkpoint_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = range(4)\n",
    "additive_weights = [model.conv.additive_mod_layers[f'additive-{i}'].weight.detach().cpu().numpy() \n",
    "                                for i in layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.8157453e-23, 3.222276e-22, -3.1739396e-22, -5.7911973e-22]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension = run.config['benchmark_dimension']\n",
    "dimension = 0\n",
    "[w[:, dimension * 10:(dimension + 1) * 10].sum() for w in additive_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'benchmark_dimension'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-c42597ce21fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark_dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'benchmark_dimension'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0005,\n",
       " 'loss': 'CE',\n",
       " 'decay': 0.0001,\n",
       " 'epochs': 1000,\n",
       " 'mod_level': [0, 1, 2, 3],\n",
       " 'batch_size': 1500,\n",
       " 'query_order': [28, 24, 21, 26, 22, 29, 20, 23, 25, 27],\n",
       " 'test_coreset_size': 5000,\n",
       " 'accuracy_threshold': 0.95,\n",
       " 'latin_square_index': 3014,\n",
       " 'train_coreset_size': 22500,\n",
       " 'benchmark_dimension': 2,\n",
       " 'dataset_random_seed': 3014,\n",
       " 'latin_square_random_seed': 3010}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (additive-0): Linear(in_features=30, out_features=3, bias=True)\n",
       "  (additive-1): Linear(in_features=30, out_features=16, bias=True)\n",
       "  (additive-2): Linear(in_features=30, out_features=32, bias=True)\n",
       "  (additive-3): Linear(in_features=30, out_features=48, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv.additive_mod_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv.additive_mod_layers['additive-0'].weight.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[model.conv.additive_mod_layers['additive-0'].weight.detach().cpu().numpy()[:, i * 10:(i + 1) * 10].sum() for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ravel(model.conv.additive_mod_layers['additive-0'].weight.detach().cpu().numpy()[:, 20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Out[44], bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
